{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nhanes as nhanes\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/mohammad/Database/CDC/NHANES/'\n",
    "DATASET = 'diabetes' # 'diabetes', 'hypertension', 'heart', 'arthritis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "The code below loads each dataset: dataset_features, dataset_targets, dataset_costs\n",
    "\n",
    "Here, all datasets are defined explicitly (see nhanes.py) except heart which is using the automated variable selection method.\n",
    "\n",
    "Running heart experiment for the first time takes longer; however, a cache file will be produced which accelerates next runs. The cache file can also be used to extract merged variable data instead of using raw files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'diabetes':\n",
    "    ds = nhanes.Dataset(DATA_PATH)\n",
    "    ds.load_diabetes()\n",
    "    n_fe = ds.features.shape[1]\n",
    "    n_classes = 3\n",
    "    dataset_costs = ds.costs.reshape(1,-1)\n",
    "    dataset_features = ds.features\n",
    "    dataset_targets = ds.targets\n",
    "elif DATASET == 'hypertension':\n",
    "    ds = nhanes.Dataset(DATA_PATH)\n",
    "    ds.load_hypertension()\n",
    "    n_fe = ds.features.shape[1]\n",
    "    n_classes = 2\n",
    "    dataset_costs = ds.costs.reshape(1,-1)\n",
    "    dataset_features = ds.features\n",
    "    dataset_targets = ds.targets\n",
    "elif DATASET == 'heart':\n",
    "    ds = nhanes.NHANES(DATA_PATH, None)\n",
    "    ds.index(False)\n",
    "    MISSING_THRESHOLD = 0.05\n",
    "    MUINFO_THRESHOLD = 0.0\n",
    "    target_col = ['MCQ160B', 'MCQ160C','MCQ160E','MCQ160F']\n",
    "    exclude_cols = target_col + ['MCQ180B', 'MCQ180C', 'MCQ180E', 'MCQ180F']\n",
    "    include_cols = None\n",
    "    def fn_any(df_cols, threshold):\n",
    "        return (df_cols < threshold).any(axis=1).astype(np.int)\n",
    "    ds.process_supervised(target_col, exclude_cols, include_cols,\n",
    "                                  fn_any, 1.5, \n",
    "                                  MISSING_THRESHOLD, MUINFO_THRESHOLD)\n",
    "    n_fe = ds.df_features.values.shape[1]\n",
    "    n_classes = 2\n",
    "    dataset_costs = ds.costs.reshape(1,-1)\n",
    "    dataset_features = ds.df_features.values\n",
    "    dataset_targets = ds.df_targets.values\n",
    "elif DATASET == 'arthritis':\n",
    "    ds = nhanes.Dataset(DATA_PATH)\n",
    "    ds.load_arthritis()\n",
    "    n_fe = ds.features.shape[1]\n",
    "    n_classes = 2\n",
    "    dataset_costs = ds.costs.reshape(1,-1)\n",
    "    dataset_features = ds.features\n",
    "    dataset_targets = ds.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(dataset_targets.shape[0])\n",
    "dataset_features = dataset_features[perm]\n",
    "dataset_targets = dataset_targets[perm]\n",
    "\n",
    "def get_batch(n_size, phase):\n",
    "    # select indices\n",
    "    n_samples = dataset_features.shape[0]\n",
    "    n_classes = int(dataset_targets.max() + 1)\n",
    "    if phase == 'test':\n",
    "        inds_sel = np.arange(0, int(n_samples*0.15), 1)\n",
    "    elif phase == 'validation':\n",
    "        n_samples = dataset_features.shape[0]\n",
    "        inds_sel = np.arange(int(n_samples*0.15), int(n_samples*0.30), 1)\n",
    "    elif phase == 'train':\n",
    "        n_samples = dataset_features.shape[0]\n",
    "        inds_sel = np.arange(int(n_samples*0.30), n_samples, 1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    inds_sel = np.random.permutation(inds_sel)\n",
    "    batch_inds = []\n",
    "    for cl in range(n_classes):\n",
    "        inds_cl = inds_sel[dataset_targets[inds_sel] == cl]\n",
    "        batch_inds.extend(inds_cl[:n_size//n_classes])\n",
    "    batch_inds = np.random.permutation(batch_inds)\n",
    "    \n",
    "    return dataset_features[batch_inds], dataset_targets[batch_inds]\n",
    "    \n",
    "features_trn, targets_trn = get_batch(n_size=5000, phase='train')\n",
    "features_tst, targets_tst = get_batch(n_size=1000, phase='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_RFC', accu)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_SVC', accu)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(features_trn, targets_trn)\n",
    "preds_tst = clf.predict(features_tst)\n",
    "accu = np.mean(preds_tst==targets_tst)\n",
    "print('accu_tst_LR', accu)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
